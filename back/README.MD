##Задание
1.	Отобрать 10 произвольных постов какого-нибудь блогера или новостного ресурса.
2.	Написать программу, которая позволит:
	- Очистить текст от «мусорных» стоп-слов. Это слова не несущие смысловой нагрузки: служебные слова (предлоги, союзы, местоимения, частицы и т. д.), слова общей и оценочной лексики: каждый, другой, плохой и т.п., числитель-ные, даты и др. Здесь может помочь знание регулярных выражений.
	- Провести морфологический разбор (лемматизацию) текстов (т.е. привести слова к нормальной форме). Лемматизация текста — это способ анализа текста, заключающийся в приведении каждого слова в нормальную морфологическую форму для подсчета вхождений. Лемматизация также может ускорять процесс индексации и оценки уникальности страницы (например, с помощью шинглов). Допустимо использовать онлайн лемматизаторы. 
	- Определить вектор лексем для каждого текста (посчитать встречаемость каждо-го слова) и определить 10 наиболее часто встречаемых слов. 
	- Определить важность полученных 10 слов. Использовать для расчета статисти-ческую меру TF-IDF.
3.	Сделать вывод по полученным результатам.
 
*Программа получает на вход 10 текстовых файлов и файл со списком стоп-слов. Для работы были взяты случайные новостные статьи на тему культуры.*

В качестве лемматизатора была использована утилита myStem, разработанная в компании Яндекс. 
Синтаксис вызова:
`$ mystem [опции] [входной файл] [выходной файл]`
У программы есть некоторые настройки:

|   |   |
| ------------ | ------------ |
|  -n	 | Построчный режим; каждое слово печатается на новой строке. | 
| -c	 | Копировать весь ввод на вывод. То есть, не только слова, но и межсловные промежутки. Опция необходима для возврата к полному представлению текста. В случае построчного вывода (когда задана опция n) межсловные промежутки вытягиваются в одну строку, символы перевода строки заменяются на \r и/или \n. Пробел для большей видимости заменяется на подчеркивание. Символ \ заменяется на \\, подчеркивание на \_. Таким образом можно однозначно восстановить исходный текст. | 
| -w	 | Печатать только словарные слова. | 
| -l	 | Не печатать исходные словоформы, только леммы и граммемы. | 
| -i	 | Печатать грамматическую информацию, расшифровка ниже. | 
| -g	 | Склеивать информацию словоформ при одной лемме (только при включенной опции -i). | 
| -s	 | Печатать маркер конца предложения (только при включенной опции -c). | 
| ---- | ------------ |

**TF-IDF** (от англ. TF — term frequency, IDF — inverse document frequency) — стати-стическая мера, используемая для оценки важности слова в контексте документа, являю-щегося частью коллекции документов или корпуса. Вес некоторого слова пропорциона-лен частоте употребления этого слова в документе и обратно пропорционален частоте употребления слова во всех документах коллекции.

> TF  — это частотность термина, которая измеряет, насколько часто термин встреча-ется в документе (оценивается важность слова).

`TF термина а = (Количество раз, когда термин а встретился в тексте / количе-ство всех слов в тексте)`

> IDF — это обратная частотность документов. Она измеряет непосредственно важ-ность термина (уменьшает вес широкоупотребительных слов).

`IDF термина а = логарифм (от Общего количества документов / Количество до-кументов, в которых встречается термин а)`

